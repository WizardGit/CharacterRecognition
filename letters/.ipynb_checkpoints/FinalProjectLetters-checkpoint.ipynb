{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries that we need\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm # This is optional but useful\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "\n",
    "emnist_dataset = datasets.EMNIST(root='./', # here\n",
    "                                split='letters',\n",
    "                                train=True, # train split\n",
    "                                download=True, # we want to get the data\n",
    "                                transform=T.ToTensor(), # put it into tensor format\n",
    "                              )\n",
    "train_data = DataLoader(emnist_dataset,\n",
    "                        batch_size=10,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25f13858850>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ToPIL = T.ToPILImage() # Converting function\n",
    "img0 = ToPIL(single_point[0][0])\n",
    "img1 = ToPIL(single_point[0][1])\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(img0)\n",
    "axs[1].imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 ninputs=1*28*28,\n",
    "                 nhidden=512,\n",
    "                 nout=62,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(ninputs, nhidden, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nhidden, nhidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nhidden, nout, bias=True),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        x = x.view(b, -1)\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16, 5, 5])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 1, 28,28)\n",
    "x = torch.relu(nn.Conv2d(1,6,5,padding=2)(x))\n",
    "x.shape\n",
    "x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
    "x.shape\n",
    "x= torch.relu(nn.Conv2d(6, 16, 5, padding=0)(x))\n",
    "x.shape\n",
    "x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
    "x.shape\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6,5,padding=2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5, padding=0)\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84,62)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.conv1(x))\n",
    "        x =  nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
    "        x = torch.sigmoid(self.conv2(x))\n",
    "        x =  nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
    "        \n",
    "        x = x.view(-1, 5*5*16)\n",
    "        \n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=62, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██████████████▌                                                          | 1/5 [02:46<11:05, 166.30s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss: 0.5283110737800598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|█████████████████████████████▏                                           | 2/5 [05:36<08:22, 167.39s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss: 0.4336187243461609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|███████████████████████████████████████████▊                             | 3/5 [08:36<05:42, 171.32s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss: 0.39827072620391846\n"
     ]
    }
   ],
   "source": [
    "# Let's get the right torch device (preference of GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Let's set up some parameters\n",
    "learning_rate=0.001\n",
    "nepochs = 5\n",
    "ninputs=1*28*28\n",
    "nhidden=1024\n",
    "nout=62\n",
    "\n",
    "\n",
    "#model = LinearNet(ninputs=ninputs, nhidden=nhidden, nout=nout).to(device)\n",
    "model = LeNet().to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# We need an optimizer that tells us what form of gradient descent to do\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "\n",
    "# We also need a loss function\n",
    "LossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "emnist_dataset = datasets.EMNIST(root='./', # here\n",
    "                                split='byclass',\n",
    "                                train=True, # train split\n",
    "                                download=True, # we want to get the data\n",
    "                                transform=T.ToTensor(), # put it into tensor format\n",
    "                              )\n",
    "train_data = DataLoader(emnist_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        )\n",
    "\n",
    "\n",
    "# This is default on but let's just be pedantic\n",
    "model.train()\n",
    "loss_history = []\n",
    "loss = torch.Tensor([0])\n",
    "for epoch in tqdm(range(nepochs),\n",
    "                  desc=f\"Epoch\",\n",
    "                  unit=\"epoch\",\n",
    "                  disable=False):\n",
    "    for (data, label) in tqdm(train_data,\n",
    "                              desc=\"iteration\",\n",
    "                              unit=\"%\",\n",
    "                              disable=True):\n",
    "        optimizer.zero_grad(set_to_none=True) # Here we clear the gradients\n",
    "        \n",
    "        # We need to make sure the tensors are on the same device as our model\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        out = model(data)\n",
    "        \n",
    "        loss = LossFunction(out, label)\n",
    "        \n",
    "        loss.backward() # This function calculates all our gradients\n",
    "        optimizer.step() # This function does our gradient descent with those gradients\n",
    "        loss_history.append(loss.item())\n",
    "    print(f\"Epoch {epoch}: loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 3, 3, 3], expected input[200, 1, 28, 28] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-c5c2c13c9533>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0manswers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0manswers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-2cb3ea610cbe>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 442\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 3, 3, 3], expected input[200, 1, 28, 28] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "# Note that we are not plotting loss per epoch but per iteration\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Neural Network Loss\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "emnist_dataset = datasets.EMNIST(root='./', # here\n",
    "                                split='byclass',\n",
    "                                train=False, # train split\n",
    "                                download=True, # we want to get the data\n",
    "                                transform=T.ToTensor(), # put it into tensor format\n",
    "                              )\n",
    "test_data = DataLoader(emnist_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        )\n",
    "\n",
    "model.eval()\n",
    "accuracy = 0\n",
    "for (data, label) in test_data:\n",
    "    data = data.to(device)\n",
    "    label = label.to(device)\n",
    "    out = model(data)\n",
    "    answers = out.max(dim=1)[1]\n",
    "    accuracy += (answers == label).sum()\n",
    "print(f\"Total accuracy = {accuracy / len(emnist_test_dataset)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.nist.gov/itl/products-and-services/emnist-dataset#:~:text=The%20EMNIST%20Letters%20dataset%20merges,with%20the%20original%20MNIST%20dataset.\n",
    "#https://pytorch.org/vision/stable/datasets.html#emnist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
