{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#This is for Google Collab Notebook - it doesn't have torchplot installed!\n!pip install torchplot\n# Here we are importing the necessary libraries\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport torchvision\nimport matplotlib.pyplot as plt\nimport torchplot as tplt\nimport numpy as np\nimport time\nimport os\nimport copy\nimport torch.optim as optim\n\nfrom torch import nn\nfrom torch import optim\nfrom torchvision import datasets, models, transforms\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader, sampler, random_split\n\nprint(\"PyTorch Version: \",torch.__version__)\nprint(\"Torchvision Version: \",torchvision.__version__)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"We will be using the:\", device)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T23:05:46.998143Z","iopub.execute_input":"2022-03-06T23:05:46.998474Z","iopub.status.idle":"2022-03-06T23:06:11.183592Z","shell.execute_reply.started":"2022-03-06T23:05:46.998381Z","shell.execute_reply":"2022-03-06T23:06:11.182783Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n            transforms.Grayscale(num_output_channels=3),\n            transforms.Resize(227),\n            transforms.CenterCrop(227),\n            transforms.ToTensor(),\n            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])\n\n# Our two datasets\nemnist_dataset = datasets.EMNIST(root='./', split='balanced', train=True, download=True, transform=transform)\nmath_dataset   = datasets.ImageFolder('../input/handwritten-math-symbols/dataset', transform=transform)\n\n# Load dataset\ncomplete_dataset = torch.utils.data.ConcatDataset([math_dataset, emnist_dataset])\ntrain_dataset = DataLoader(complete_dataset,batch_size=10,)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T23:07:26.078735Z","iopub.execute_input":"2022-03-06T23:07:26.079009Z","iopub.status.idle":"2022-03-06T23:07:56.737662Z","shell.execute_reply.started":"2022-03-06T23:07:26.078980Z","shell.execute_reply":"2022-03-06T23:07:56.736955Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data = iter(train_dataset) # Let's iterate on it\nsingle_point = next(data)\nToPIL = transforms.ToPILImage() # Converting function\nimg0 = ToPIL(single_point[0][0])\nimg1 = ToPIL(single_point[0][1])\n# Plotting\nfig, axs = plt.subplots(1,2)\naxs[0].imshow(img0)\naxs[1].imshow(img1)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T23:07:56.739341Z","iopub.execute_input":"2022-03-06T23:07:56.739602Z","iopub.status.idle":"2022-03-06T23:07:57.154082Z","shell.execute_reply.started":"2022-03-06T23:07:56.739568Z","shell.execute_reply":"2022-03-06T23:07:57.153413Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class LeNet(nn.Module):\n    def __init__(self, nclasses=68):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 6,5,padding=2)\n        self.conv2 = nn.Conv2d(6,16,5, padding=0)\n        self.fc1 = nn.Linear(5*5*16, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84,nclasses)\n        \n    def forward(self, x):\n        x = torch.sigmoid(self.conv1(x))\n        x =  nn.MaxPool2d(kernel_size=2, stride=2)(x)\n        x = torch.sigmoid(self.conv2(x))\n        x =  nn.MaxPool2d(kernel_size=2, stride=2)(x)\n        \n        x = x.view(-1, 5*5*16)\n        \n        x = torch.sigmoid(self.fc1(x))\n        x = torch.sigmoid(self.fc2(x))\n        x = self.fc3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-03-06T23:07:57.155174Z","iopub.execute_input":"2022-03-06T23:07:57.158020Z","iopub.status.idle":"2022-03-06T23:07:57.165869Z","shell.execute_reply.started":"2022-03-06T23:07:57.157989Z","shell.execute_reply":"2022-03-06T23:07:57.165087Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Code from https://medium.com/analytics-vidhya/alexnet-a-simple-implementation-using-pytorch-30c14e8b6db2\nclass AlexNet(nn.Module):\n    def __init__(self, nclasses=68):\n        super(AlexNet, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels= 96, kernel_size= 11, stride=4, padding=0 )\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride= 1, padding= 2)\n        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride= 1, padding= 1)\n        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n        self.fc1  = nn.Linear(in_features= 9216, out_features= 4096)\n        self.fc2  = nn.Linear(in_features= 4096, out_features= 4096)\n        self.fc3 = nn.Linear(in_features=4096 , out_features=nclasses)\n\n\n    def forward(self,x):\n        x = F.relu(self.conv1(x))\n        x = self.maxpool(x)\n        x = F.relu(self.conv2(x))\n        x = self.maxpool(x)\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = F.relu(self.conv5(x))\n        x = self.maxpool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-03-06T23:07:57.167914Z","iopub.execute_input":"2022-03-06T23:07:57.168130Z","iopub.status.idle":"2022-03-06T23:07:57.184673Z","shell.execute_reply.started":"2022-03-06T23:07:57.168104Z","shell.execute_reply":"2022-03-06T23:07:57.183818Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Will append the test accuracy to the test_accuracy_history[]\ndef evaluate(model, test_data, test_accuracy_history, test_image_datasets_len):\n    with torch.no_grad():\n        test_accuracy = 0\n        for (data, label) in test_data:\n            data = data.to(device)\n            label = label.to(device)\n            out = model(data)\n            answers = out.max(dim=1)[1]\n            test_accuracy += (answers == label).sum()\n    # Append the testing accuracy\n    test_accuracy = test_accuracy / test_image_datasets_len * 100\n    test_accuracy_history.append(test_accuracy)\n    return test_accuracy\n# Does not accept the test_accuracy_history[]\ndef evaluateAcc(model, test_data, test_data_len):\n    with torch.no_grad():\n        test_accuracy = 0\n        for (data, label) in test_data:\n            data = data.to(device)\n            label = label.to(device)\n            out = model(data)\n            answers = out.max(dim=1)[1]\n            test_accuracy += (answers == label).sum()\n    # Append the testing accuracy\n    test_accuracy = test_accuracy / test_data_len * 100\n    return test_accuracy","metadata":{"execution":{"iopub.status.busy":"2022-03-06T23:07:57.187802Z","iopub.execute_input":"2022-03-06T23:07:57.188467Z","iopub.status.idle":"2022-03-06T23:07:57.199637Z","shell.execute_reply.started":"2022-03-06T23:07:57.188421Z","shell.execute_reply":"2022-03-06T23:07:57.198874Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def super_plotter(loss_history, test_accuracy_history, train_accuracy_history):\n    # Plot the loss per iteration\n    tplt.plot(loss_history, label=\"Loss\")\n    tplt.title(\"Neural Network Loss\")\n    tplt.xlabel(\"Number of iterations\")\n    tplt.ylabel(\"Loss History\")\n    tplt.legend(loc='upper right')\n    tplt.show()\n    # Plot the accuracy per epoch\n    tplt.plot(test_accuracy_history, label=\"Test\")\n    tplt.plot(train_accuracy_history, label=\"Train\")\n    tplt.title(\"Neural Network Accuracy\")\n    tplt.xlabel(\"Epoch Number\")\n    tplt.ylabel(\"Accuracy\")\n    tplt.legend(loc='lower right')\n    tplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T23:07:57.202462Z","iopub.execute_input":"2022-03-06T23:07:57.203427Z","iopub.status.idle":"2022-03-06T23:07:57.213292Z","shell.execute_reply.started":"2022-03-06T23:07:57.203385Z","shell.execute_reply":"2022-03-06T23:07:57.212290Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def super_model_trainer(model, train_dataset, train_dataloader, test_dataset, test_dataloader, batch_size, optimizer, nepochs): \n    model.train()\n    loss_history = []\n    test_accuracy_history = []\n    train_accuracy_history = []\n    loss = torch.Tensor([0])\n    for epoch in tqdm(range(nepochs), desc=f\"Epoch\", unit=\"epoch\", disable=False):\n        accuracy = 0\n        for (data, label) in tqdm(train_dataloader, desc=\"iteration\", unit=\"%\", disable=True):\n            # Here we clear the gradients\n            optimizer.zero_grad(set_to_none=True)        \n            # We need to make sure the tensors are on the same device as our model\n            data = data.to(device)\n            label = label.to(device)\n            out = model(data)\n        \n            loss = LossFunction(out, label)\n        \n            loss.backward() # This function calculates all our gradients\n            optimizer.step() # This function does our gradient descent with those gradients\n            loss_history.append(loss.item())\n            answers = out.max(dim=1)[1]\n            accuracy += (answers == label).sum()\n        # Append the training accuracy\n        accuracy = accuracy / len(train_dataset)*100\n        train_accuracy_history.append(accuracy)\n    \n        #let's get the test accuracy to see how well it generalizes\n        test_accuracy = evaluate(model, test_dataloader, test_accuracy_history, len(test_dataset))\n        #Print the results\n        print(f\"Epoch: {epoch} \\n Loss: {loss.item()} \\n Train Accuracy: {accuracy:.2f}% \\n Test Accuracy: {test_accuracy:.2f}%\")\n    super_plotter(loss_history, test_accuracy_history, train_accuracy_history)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T23:07:57.215155Z","iopub.execute_input":"2022-03-06T23:07:57.215501Z","iopub.status.idle":"2022-03-06T23:07:57.226796Z","shell.execute_reply.started":"2022-03-06T23:07:57.215458Z","shell.execute_reply":"2022-03-06T23:07:57.225780Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Let's set up some parameters\nlearning_rate=0.001\nnepochs = 5\nnclasses=53\nbatch_size = 64\n\n\n#model = LeNet(nclasses).to(device)\nmodel = AlexNet(nclasses).to(device)\nprint(model)\n\noptimizer = torch.optim.Adam(model.parameters(), learning_rate)\nLossFunction = nn.CrossEntropyLoss()\n\ntransformAlexNet = transforms.Compose([\n            transforms.Grayscale(num_output_channels=3),\n            transforms.Resize(227),\n            transforms.CenterCrop(227),\n            transforms.ToTensor(),\n            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])\ntransformLeNet = transforms.Compose([\n            transforms.Grayscale(num_output_channels=1),\n            transforms.Resize(28),\n            transforms.CenterCrop(28),\n            transforms.ToTensor(),\n            #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        ])\n\ntransform = transformAlexNet\n\n# Create the emnist train and test datasets\nemnist_train_dataset = datasets.EMNIST(root='./', split='balanced', train=True, download=True, transform=transform)\nemnist_test_dataset = datasets.EMNIST(root='./', split='balanced', train=False, download=False, transform=transform)\n\n# Create the math train and test datasets\nmath_dataset = datasets.ImageFolder('../input/customarchive/CustomArchive/dataset', transform=transform)\n#math_dataset = datasets.ImageFolder('./CustomArchive/dataset', transform=transform)\n\nmath_train_dataset_len = int(len(math_dataset)*0.80)\nmath_test_dataset_len = int(len(math_dataset) - math_train_dataset_len)\nmath_train_dataset, math_test_dataset = random_split(math_dataset, [math_train_dataset_len, math_test_dataset_len])\n\n# Combine the train and test datasets and shuffle them together\ntrain_dataset = torch.utils.data.ConcatDataset([math_train_dataset, emnist_train_dataset])\ntrain_dataloader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\ntest_dataset = torch.utils.data.ConcatDataset([math_test_dataset, emnist_test_dataset])\ntest_dataloader = DataLoader(test_dataset,batch_size=batch_size,shuffle=True)\n\n#Training \nsuper_model_trainer(model, train_dataset, train_dataloader, test_dataset, test_dataloader, batch_size, optimizer, nepochs)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T23:07:57.228608Z","iopub.execute_input":"2022-03-06T23:07:57.229247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_emnist = DataLoader(emnist_test_dataset,batch_size=batch_size,shuffle=True)\ntest_data_math = DataLoader(math_test_dataset,batch_size=batch_size, shuffle=True)\n\n\ntest_accuracy_emnist = evaluateAcc(model, test_data_emnist, len(emnist_test_dataset))\ntest_accuracy_math = evaluateAcc(model, test_data_math, math_test_dataset_len)\n\n\n\nm_dataset = datasets.ImageFolder('../input/handwritten-math-symbols/dataset', transform=transform)\nm_dataloader = DataLoader(m_dataset,batch_size=batch_size,shuffle=True)\nm_accuracy = evaluateAcc(model, m_dataloader, len(m_dataset))\n\n#Print the results\nprint(f\"EMNIST Accuracy: {test_accuracy_emnist:.2f}%\")\nprint(f\"Operator Accuracy: {test_accuracy_math:.2f}%\")\nprint(f\"Full Archive Accuracy: {m_accuracy:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}